{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing a Neural Network\n",
    "In this exercise we will develop a neural network with fully-connected layers to perform classification, and test it out on the CIFAR-10 dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# A bit of setup\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cs231n.classifiers.neural_net import TwoLayerNet\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "def rel_error(x, y):\n",
    "  \"\"\" returns relative error \"\"\"\n",
    "  return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the class `TwoLayerNet` in the file `cs231n/classifiers/neural_net.py` to represent instances of our network. The network parameters are stored in the instance variable `self.params` where keys are string parameter names and values are numpy arrays. Below, we initialize toy data and a toy model that we will use to develop your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<cs231n.classifiers.neural_net.TwoLayerNet object at 0x7f311f727610>\n",
      "[[ 16.24345364  -6.11756414  -5.28171752 -10.72968622]\n",
      " [  8.65407629 -23.01538697  17.44811764  -7.61206901]\n",
      " [  3.19039096  -2.49370375  14.62107937 -20.60140709]\n",
      " [ -3.22417204  -3.84054355  11.33769442 -10.99891267]\n",
      " [ -1.72428208  -8.77858418   0.42213747   5.82815214]]\n",
      "[0 1 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "# Create a small net and some toy data to check your implementations.\n",
    "# Note that we set the random seed for repeatable experiments.\n",
    "\n",
    "input_size = 4\n",
    "hidden_size = 10\n",
    "num_classes = 3\n",
    "num_inputs = 5\n",
    "\n",
    "def init_toy_model():\n",
    "  np.random.seed(0)\n",
    "  return TwoLayerNet(input_size, hidden_size, num_classes, std=1e-1)\n",
    "\n",
    "def init_toy_data():\n",
    "  np.random.seed(1)\n",
    "  X = 10 * np.random.randn(num_inputs, input_size)\n",
    "  y = np.array([0, 1, 2, 2, 1])\n",
    "  return X, y\n",
    "\n",
    "net = init_toy_model()\n",
    "X, y = init_toy_data()\n",
    "print net\n",
    "print X\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute scores\n",
    "Open the file `cs231n/classifiers/neural_net.py` and look at the method `TwoLayerNet.loss`. This function is very similar to the loss functions you have written for the SVM and Softmax exercises: It takes the data and weights and computes the class scores, the loss, and the gradients on the parameters. \n",
    "\n",
    "Implement the first part of the forward pass which uses the weights and biases to compute the scores for all inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "correct scores:\n",
      "[[-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]]\n",
      "\n",
      "Difference between your scores and correct scores:\n",
      "3.68027209255e-08\n"
     ]
    }
   ],
   "source": [
    "scores = net.loss(X)\n",
    "print 'Your scores:'\n",
    "print scores\n",
    "print\n",
    "print 'correct scores:'\n",
    "correct_scores = np.asarray([\n",
    "  [-0.81233741, -1.27654624, -0.70335995],\n",
    "  [-0.17129677, -1.18803311, -0.47310444],\n",
    "  [-0.51590475, -1.01354314, -0.8504215 ],\n",
    "  [-0.15419291, -0.48629638, -0.52901952],\n",
    "  [-0.00618733, -0.12435261, -0.15226949]])\n",
    "print correct_scores\n",
    "print\n",
    "\n",
    "# The difference should be very small. We get < 1e-7\n",
    "print 'Difference between your scores and correct scores:'\n",
    "print np.sum(np.abs(scores - correct_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward pass: compute loss\n",
    "In the same function, implement the second part that computes the data and regularizaion loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.30378789133\n",
      "Difference between your loss and correct loss:\n",
      "1.79412040779e-13\n"
     ]
    }
   ],
   "source": [
    "loss, _ = net.loss(X, y, reg=0.1)\n",
    "correct_loss = 1.30378789133\n",
    "\n",
    "# should be very small, we get < 1e-12\n",
    "print loss\n",
    "print 'Difference between your loss and correct loss:'\n",
    "print np.sum(np.abs(loss - correct_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass\n",
    "Implement the rest of the function. This will compute the gradient of the loss with respect to the variables `W1`, `b1`, `W2`, and `b2`. Now that you (hopefully!) have a correctly implemented forward pass, you can debug your backward pass using a numeric gradient check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b2\n",
      "b2 max relative error: 6.666667e-01\n",
      "W2\n",
      "W2 max relative error: 1.000000e+00\n",
      "W1\n",
      "W1 max relative error: 1.000000e+00\n",
      "b1\n",
      "b1 max relative error: 1.000000e+00\n"
     ]
    }
   ],
   "source": [
    "from cs231n.gradient_check import eval_numerical_gradient\n",
    "\n",
    "# Use numeric gradient checking to check your implementation of the backward pass.\n",
    "# If your implementation is correct, the difference between the numeric and\n",
    "# analytic gradients should be less than 1e-8 for each of W1, W2, b1, and b2.\n",
    "\n",
    "loss, grads = net.loss(X, y, reg=0.1)\n",
    "\n",
    "# these should all be less than 1e-8 or so\n",
    "for param_name in grads:\n",
    "  print param_name\n",
    "  f = lambda W: net.loss(X, y, reg=0.1)[0]\n",
    "  param_grad_num = eval_numerical_gradient(f, net.params[param_name], verbose=False)\n",
    "  print '%s max relative error: %e' % (param_name, rel_error(param_grad_num, grads[param_name]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the network\n",
    "To train the network we will use stochastic gradient descent (SGD), similar to the SVM and Softmax classifiers. Look at the function `TwoLayerNet.train` and fill in the missing sections to implement the training procedure. This should be very similar to the training procedure you used for the SVM and Softmax classifiers. You will also have to implement `TwoLayerNet.predict`, as the training process periodically performs prediction to keep track of accuracy over time while the network trains.\n",
    "\n",
    "Once you have implemented the method, run the code below to train a two-layer network on toy data. You should achieve a training loss less than 0.2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "scores before:  [[-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.17129677 -1.18803311 -0.47310444]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.81233741 -1.27654624 -0.70335995]\n",
      " [-0.15419291 -0.48629638 -0.52901952]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.51590475 -1.01354314 -0.8504215 ]\n",
      " [-0.00618733 -0.12435261 -0.15226949]\n",
      " [-0.17129677 -1.18803311 -0.47310444]]\n",
      "scores later:  [[-0.16510944 -1.18184578 -0.46691712]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.16510944 -1.18184578 -0.46691712]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.80615009 -1.27035892 -0.69717262]\n",
      " [-0.14800559 -0.48010906 -0.5228322 ]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [-0.50971743 -1.00735582 -0.84423417]\n",
      " [ 0.         -0.11816528 -0.14608217]\n",
      " [-0.16510944 -1.18184578 -0.46691712]]\n",
      "exp_scores:  [[ 0.84780091  0.30671209  0.62693205]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.84780091  0.30671209  0.62693205]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.44657403  0.28073085  0.49799132]\n",
      " [ 0.8624263   0.61871591  0.59283913]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 0.60066529  0.36518332  0.42988645]\n",
      " [ 1.          0.88854918  0.8640867 ]\n",
      " [ 0.84780091  0.30671209  0.62693205]]\n",
      "corr_scores.shape : (200, 1)\n",
      "Final training loss:  1.24199380249\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnAAAAH4CAYAAADKGNCLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb68cb0a210>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = init_toy_model()\n",
    "stats = net.train(X, y, X, y,\n",
    "            learning_rate=1e-1, reg=1e-5,\n",
    "            num_iters=100, verbose=False)\n",
    "\n",
    "print 'Final training loss: ', stats['loss_history'][-1]\n",
    "\n",
    "# plot the loss history\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.xlabel('iteration')\n",
    "plt.ylabel('training loss')\n",
    "plt.title('Training Loss history')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "Now that you have implemented a two-layer network that passes gradient checks and works on toy data, it's time to load up our favorite CIFAR-10 data so we can use it to train a classifier on a real dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape:  (49000, 3072)\n",
      "Train labels shape:  (49000,)\n",
      "Validation data shape:  (1000, 3072)\n",
      "Validation labels shape:  (1000,)\n",
      "Test data shape:  (1000, 3072)\n",
      "Test labels shape:  (1000,)\n"
     ]
    }
   ],
   "source": [
    "from cs231n.data_utils import load_CIFAR10\n",
    "\n",
    "def get_CIFAR10_data(num_training=49000, num_validation=1000, num_test=1000):\n",
    "    \"\"\"\n",
    "    Load the CIFAR-10 dataset from disk and perform preprocessing to prepare\n",
    "    it for the two-layer neural net classifier. These are the same steps as\n",
    "    we used for the SVM, but condensed to a single function.  \n",
    "    \"\"\"\n",
    "    # Load the raw CIFAR-10 data\n",
    "    cifar10_dir = 'cs231n/datasets/cifar-10-batches-py'\n",
    "    X_train, y_train, X_test, y_test = load_CIFAR10(cifar10_dir)\n",
    "        \n",
    "    # Subsample the data\n",
    "    mask = range(num_training, num_training + num_validation)\n",
    "    X_val = X_train[mask]\n",
    "    y_val = y_train[mask]\n",
    "    mask = range(num_training)\n",
    "    X_train = X_train[mask]\n",
    "    y_train = y_train[mask]\n",
    "    mask = range(num_test)\n",
    "    X_test = X_test[mask]\n",
    "    y_test = y_test[mask]\n",
    "\n",
    "    # Normalize the data: subtract the mean image\n",
    "    mean_image = np.mean(X_train, axis=0)\n",
    "    X_train -= mean_image\n",
    "    X_val -= mean_image\n",
    "    X_test -= mean_image\n",
    "\n",
    "    # Reshape data to rows\n",
    "    X_train = X_train.reshape(num_training, -1)\n",
    "    X_val = X_val.reshape(num_validation, -1)\n",
    "    X_test = X_test.reshape(num_test, -1)\n",
    "\n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test\n",
    "\n",
    "\n",
    "# Invoke the above function to get our data.\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = get_CIFAR10_data()\n",
    "print 'Train data shape: ', X_train.shape\n",
    "print 'Train labels shape: ', y_train.shape\n",
    "print 'Validation data shape: ', X_val.shape\n",
    "print 'Validation labels shape: ', y_val.shape\n",
    "print 'Test data shape: ', X_test.shape\n",
    "print 'Test labels shape: ', y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a network\n",
    "To train our network we will use SGD with momentum. In addition, we will adjust the learning rate with an exponential learning rate schedule as optimization proceeds; after each epoch, we will reduce the learning rate by multiplying it by a decay rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 / 1000: loss 2.302954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cs231n/classifiers/neural_net.py:138: RuntimeWarning: invalid value encountered in multiply\n",
      "  dscores = np.exp(scores) * dexp_scores\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 100 / 1000: loss nan\n",
      "iteration 200 / 1000: loss nan\n",
      "iteration 300 / 1000: loss nan\n",
      "iteration 400 / 1000: loss nan\n",
      "iteration 500 / 1000: loss nan\n",
      "iteration 600 / 1000: loss nan\n",
      "iteration 700 / 1000: loss nan\n",
      "iteration 800 / 1000: loss nan\n",
      "iteration 900 / 1000: loss nan\n",
      "Validation accuracy:  0.087\n"
     ]
    }
   ],
   "source": [
    "input_size = 32 * 32 * 3\n",
    "hidden_size = 50\n",
    "num_classes = 10\n",
    "net = TwoLayerNet(input_size, hidden_size, num_classes)\n",
    "\n",
    "# Train the network\n",
    "stats = net.train(X_train, y_train, X_val, y_val,\n",
    "            num_iters=1000, batch_size=200,\n",
    "            learning_rate=1e-4, learning_rate_decay=0.95,\n",
    "            reg=0.5, verbose=True)\n",
    "\n",
    "# Predict on the validation set\n",
    "val_acc = (net.predict(X_val) == y_val).mean()\n",
    "print 'Validation accuracy: ', val_acc\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug the training\n",
    "With the default parameters we provided above, you should get a validation accuracy of about 0.29 on the validation set. This isn't very good.\n",
    "\n",
    "One strategy for getting insight into what's wrong is to plot the loss function and the accuracies on the training and validation sets during optimization.\n",
    "\n",
    "Another strategy is to visualize the weights that were learned in the first layer of the network. In most neural networks trained on visual data, the first layer weights typically show some visible structure when visualized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAm0AAAH4CAYAAAAYSNrTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb68ff9e9d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the loss function and train / validation accuracies\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(stats['loss_history'])\n",
    "plt.title('Loss history')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(stats['train_acc_history'], label='train')\n",
    "plt.plot(stats['val_acc_history'], label='val')\n",
    "plt.title('Classification accuracy history')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Clasification accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAHeCAYAAACok2NLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fb68ff9e990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from cs231n.vis_utils import visualize_grid\n",
    "\n",
    "# Visualize the weights of the network\n",
    "\n",
    "def show_net_weights(net):\n",
    "  W1 = net.params['W1']\n",
    "  W1 = W1.reshape(32, 32, 3, -1).transpose(3, 0, 1, 2)\n",
    "  plt.imshow(visualize_grid(W1, padding=3).astype('uint8'))\n",
    "  plt.gca().axis('off')\n",
    "  plt.show()\n",
    "\n",
    "show_net_weights(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune your hyperparameters\n",
    "\n",
    "**What's wrong?**. Looking at the visualizations above, we see that the loss is decreasing more or less linearly, which seems to suggest that the learning rate may be too low. Moreover, there is no gap between the training and validation accuracy, suggesting that the model we used has low capacity, and that we should increase its size. On the other hand, with a very large model we would expect to see more overfitting, which would manifest itself as a very large gap between the training and validation accuracy.\n",
    "\n",
    "**Tuning**. Tuning the hyperparameters and developing intuition for how they affect the final performance is a large part of using Neural Networks, so we want you to get a lot of practice. Below, you should experiment with different values of the various hyperparameters, including hidden layer size, learning rate, numer of training epochs, and regularization strength. You might also consider tuning the learning rate decay, but you should be able to get good performance using the default value.\n",
    "\n",
    "**Approximate results**. You should be aim to achieve a classification accuracy of greater than 48% on the validation set. Our best network gets over 52% on the validation set.\n",
    "\n",
    "**Experiment**: You goal in this exercise is to get as good of a result on CIFAR-10 as you can, with a fully-connected Neural Network. For every 1% above 52% on the Test set we will award you with one extra bonus point. Feel free implement your own techniques (e.g. PCA to reduce dimensionality, or adding dropout, or adding features to the solver, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_net = None # store the best model into this \n",
    "\n",
    "#################################################################################\n",
    "# TODO: Tune hyperparameters using the validation set. Store your best trained  #\n",
    "# model in best_net.                                                            #\n",
    "#                                                                               #\n",
    "# To help debug your network, it may help to use visualizations similar to the  #\n",
    "# ones we used above; these visualizations will have significant qualitative    #\n",
    "# differences from the ones we saw above for the poorly tuned network.          #\n",
    "#                                                                               #\n",
    "# Tweaking hyperparameters by hand can be fun, but you might find it useful to  #\n",
    "# write code to sweep through possible combinations of hyperparameters          #\n",
    "# automatically like we did on the previous exercises.                          #\n",
    "#################################################################################\n",
    "pass\n",
    "#################################################################################\n",
    "#                               END OF YOUR CODE                                #\n",
    "#################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualize the weights of the best network\n",
    "show_net_weights(best_net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run on the test set\n",
    "When you are done experimenting, you should evaluate your final trained network on the test set; you should get above 48%.\n",
    "\n",
    "**We will give you extra bonus point for every 1% of accuracy above 52%.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_acc = (best_net.predict(X_test) == y_test).mean()\n",
    "print 'Test accuracy: ', test_acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
